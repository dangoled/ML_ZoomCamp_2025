{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eb61e8e-723b-43bb-a291-1970ca7fa2b2",
   "metadata": {},
   "source": [
    "### <CENTER>ML ZOOMCAMP 2025 </CENTER>\n",
    "### <CENTER>04 Evaluation - Homework</CENTER>\n",
    "### <CENTER>ANGOLE DANIEL</CENTER>\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "In this homework, we will use the lead scoring dataset Bank Marketing dataset. Download it from here.\n",
    "\n",
    "In this dataset our desired target for classification task will be converted variable - has the client signed up to the platform or not.\n",
    "\n",
    "#### Data preparation\n",
    "\n",
    "- Check if the missing values are presented in the features.\n",
    "- If there are missing values:\n",
    "    - For caterogiral features, replace them with 'NA'\n",
    "    - For numerical features, replace with with 0.0\n",
    "\n",
    "Split the data into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split function for that with random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d5142b8-1e59-4516-b5c5-dd6059661a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d95d76a-187b-4d8b-aa58-837944181c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-19 07:40:45--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-10-19 07:40:45 (60.0 MB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3e5d9c-8415-40a2-a70c-bdab078b3aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"course_lead_scoring.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b72e0d9-1b77-4915-a66d-66c6d6f6d61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd44a547-468b-476d-8253-4ed3e2b14833",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "numerical_features = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "df[categorical_features] = df[categorical_features].fillna(\"NA\")\n",
    "df[numerical_features] = df[numerical_features].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36dc7b3f-bb4a-49bf-b790-eb7bd5102a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f4d8f5-b72c-4485-9d1c-035a55af0812",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size= 0.2, random_state= 1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size= 0.25, random_state= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d17f596-14fb-4b54-a0ba-26137a5e2717",
   "metadata": {},
   "source": [
    "<b> Question 1: ROC AUC feature importance </b>\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that\n",
    "\n",
    "- For each numerical variable, use it as score (aka prediction) and compute the AUC with the y variable as ground truth.\n",
    "- Use the training dataset for that\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. -df_train['balance'])\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target variable. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- lead_score\n",
    "- number_of_courses_viewed\n",
    "- interaction_count\n",
    "- annual_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e53524-d200-44ad-891b-cc6f8e92b0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b438aed-8ae1-435d-aa69-25d827bee0f5",
   "metadata": {},
   "source": [
    "<b> Question 2: Training the model </b>\n",
    "\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "\n",
    "    LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.32\n",
    "- 0.52\n",
    "- 0.72\n",
    "- 0.92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc645f91-78c4-47a4-9cf0-774b3ccc2bc9",
   "metadata": {},
   "source": [
    "<b> Question 3: Precision and Recall </b>\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "- Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "- For each threshold, compute precision and recall\n",
    "- Plot them\n",
    "\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "- 0.145\n",
    "- 0.345\n",
    "- 0.545\n",
    "- 0.745"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986f9345-e8a5-47b4-89ca-5b0979e33be8",
   "metadata": {},
   "source": [
    "<b> Question 4: F1 score </b>\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "$$F_1 = \\frac{P.R}{P+R}$$\n",
    "\n",
    "Where \n",
    "P is precision and R is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.14\n",
    "- 0.34\n",
    "- 0.54\n",
    "- 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c282c32d-90e4-437d-9d76-4c2002d0784c",
   "metadata": {},
   "source": [
    "<b> Question 5: 5-Fold CV </b>\n",
    "\n",
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "    KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "- Iterate over different folds of df_full_train\n",
    "- Split the data into train and validation\n",
    "- Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "- Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard deviation of the scores across different folds?\n",
    "\n",
    "- 0.0001\n",
    "- 0.006\n",
    "- 0.06\n",
    "- 0.36"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7fb738-a391-45e1-b6e3-9d3f399dd3f8",
   "metadata": {},
   "source": [
    "<b> Question 6: Hyperparameter Tuning </b>\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "- Iterate over the following C values: [0.000001, 0.001, 1]\n",
    "- Initialize KFold with the same parameters as previously\n",
    "- Use these parameters for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "- Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "\n",
    "Which C leads to the best mean score?\n",
    "\n",
    "- 0.000001\n",
    "- 0.001\n",
    "- 1\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc660e3-fb2b-46dc-8476-4c864269dab7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
